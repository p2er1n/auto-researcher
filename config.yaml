# 采集任务配置
tasks:
  - name: "具身智能 & VLA 学术论文"
    interval: "6h"
    
    # 数据源配置
    sources:
      # DBLP RSS 订阅 - 获取最新会议论文集
      - type: "dblp"
        name: "DBLP CV/NeurIPS会议"
        url: "https://dblp.org"
        auth:
          # 订阅的会议列表
          conferences:
            - "cvpr"
            - "iccv"
            - "neurips"
            - "iclr"
            - "aaai"
            - "icml"
            - "iros"
            - "coRL"
            - "RSS"
          max_results: 100  # 不限制，由时间过滤
      
      # DBLP 搜索 (可选，补充搜索)
      - type: "dblp"
        name: "DBLP 具身智能搜索"
        url: "https://dblp.org"
        auth:
          query: "vision language robot"
          max_results: 100
      
      # arXiv RSS (每天更新一次)
      - type: "arxiv_rss"
        name: "arXiv RSS"
        url: "https://rss.arxiv.org"
        auth:
          categories:
            - "cs.CV"
            - "cs.AI"
            - "cs.LG"
            - "cs.RO"
            - "cs.CL"
          max_results: 100
      
      # arXiv 库 (使用 Python arxiv 库，更稳定)
      - type: "arxiv_lib"
        name: "arXiv Library"
        url: "https://arxiv.org"
        auth:
          categories:
            - "cs.CV"
            - "cs.AI"
            - "cs.LG"
            - "cs.RO"
            - "cs.CL"
          max_results: 100
    
    # 筛选规则
    filters:
      # 时间过滤 - 只保留最近 180 天（约半年）的论文
      - type: "date"
        days: 180
        action: "keep"
      
      # 关键词 - 具身智能/VLA方向
      - type: "keyword"
        keywords: [
          "VLA", "Vision-Language-Action", "Vision Language Action",
          "embodied", "embodied intelligence", "具身智能",
          "robot", "robotics", "robotic", "机器人",
          "manipulation", "grasping", "dexterous manipulation",
          "navigation", "visual navigation", "language navigation",
          "humanoid", "android", "仿人机器人",
          "sim-to-real", "domain randomization", "sim2real",
          "reinforcement learning", "RL", "强化学习",
          "imitation learning", "behavior cloning", "模仿学习",
          "LLM robot", "large language model robot", "语言模型机器人",
          "multimodal", "multimodal learning",
          "foundation model", "visual foundation model",
          "scene understanding", "3D understanding",
          "object detection", "object recognition",
          "semantic understanding", "scene graph"
        ]
        action: "keep"
        scope: "all"
        case_sensitive: false
        match: "any"
      
      # 长度筛选
      - type: "length"
        min: 10
      
      # 去重
      - type: "deduplicate"
        fields: ["title"]
    
    # 模板配置
    template: "default"
    output: "embodied-vla-papers"
    
    variables:
      site_title: "具身智能 & VLA 学术论文"
      site_description: "自动追踪 CVPR, NeurIPS, ICLR, CoRL, RSS 等顶会最新具身智能、VLA、机器人相关论文"

# 全局设置
settings:
  timezone: "Asia/Shanghai"
  max_workers: 3
  timeout: 30
  retry: 3
  user_agent: "AutoResearcher/1.0 (GitHub Actions)"

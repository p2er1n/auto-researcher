name: AutoResearcher

on:
  schedule:
    - cron: '0 */6 * * *'
  
  workflow_dispatch:
  
  push:
    branches:
      - master
    paths:
      - 'config.yaml'
      - 'src/**'
      - 'templates/**'

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: false

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: false
      
      - name: Checkout gh-pages
        uses: actions/checkout@v4
        with:
          ref: gh-pages
          path: gh-pages
          persist-credentials: false
        continue-on-error: true
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run AutoResearcher
        env:
          GITHUB_TOKEN: ${{ github.token }}
          API_TOKEN: ${{ secrets.API_TOKEN }}
        run: |
          python src/main.py --config config.yaml --output dists
      
      - name: Copy, cleanup and generate index
        run: |
          mkdir -p gh-pages
          cp -r dists/* gh-pages/ 2>/dev/null || true
          
          # 清理旧构建，只保留最新的5个
          cd gh-pages
          # 获取所有时间戳目录，按修改时间倒序
          dirs=$(ls -td */ 2>/dev/null | head -10)
          count=$(echo "$dirs" | wc -l)
          if [ "$count" -gt 5 ]; then
            # 删除多余的旧目录
            echo "$dirs" | tail -n +6 | xargs rm -rf 2>/dev/null || true
            echo "已清理旧构建，保留最新5个"
          fi
          
          # 使用 Python 生成 index.html（带标题）
          python3 << 'PYEOF'
import os
import glob

dirs = []
for d in glob.glob('*/'):
    if os.path.isfile(os.path.join(d, 'index.html')):
        # 尝试读取标题
        title = d  # 默认使用目录名
        try:
            with open(os.path.join(d, 'index.html'), 'r', encoding='utf-8') as f:
                content = f.read()
                # 查找 <title> 标签
                if '<title>' in content and '</title>' in content:
                    start = content.find('<title>') + 7
                    end = content.find('</title>', start)
                    if end > start:
                        title = content[start:end].strip()
                        # 简化标题
                        title = title.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')
        except:
            pass
        
        dirs.append({'name': d.rstrip('/'), 'title': title, 'mtime': os.path.getmtime(d)})

# 按时间倒序
dirs.sort(key=lambda x: x['mtime'], reverse=True)

html = '''<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>AutoResearcher - 网站列表</title>
<style>
body { font-family: system-ui; max-width: 900px; margin: 50px auto; padding: 20px; }
h1 { color: #333; }
ul { list-style: none; padding: 0; }
li { padding: 12px; margin: 8px 0; background: #f5f5f5; border-radius: 6px; }
a { color: #0066cc; text-decoration: none; font-size: 1.1em; }
a:hover { text-decoration: underline; }
.date { color: #888; font-size: 0.85em; margin-left: 10px; }
</style>
</head>
<body>
<h1>AutoResearcher - 网站列表</h1>
<ul>
'''

for d in dirs:
    html += f'<li><a href="{d["name"]}/index.html">{d["title"]}</a><span class="date">({d["name"]})</span></li>\n'

html += '''</ul>
</body>
</html>
'''

with open('index.html', 'w', encoding='utf-8') as f:
    f.write(html)

print(f'Generated index with {len(dirs)} entries')
PYEOF
      
      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ github.token }}
          publish_dir: ./gh-pages
          publish_branch: gh-pages
          user_name: AutoResearcher
          user_email: bot@autoreseacher.dev
